From daa638e44644835b63e604b2faf5a44b757d9a41 Mon Sep 17 00:00:00 2001
From: Shijie Qin <shijie.qin@nxp.com>
Date: Fri, 5 Jul 2019 16:05:02 +0800
Subject: [PATCH 13/52] MLK-22206 VPU Decoder: modify vpu log print method

vpu error log modify to non-maskable
VPU_WARN / VPU_EVENT / VPU_INFO info unified use bit map method

Signed-off-by: Shijie Qin <shijie.qin@nxp.com>
Reviewed-by: ming_qian <ming.qian@nxp.com>
---
 drivers/mxc/vpu_malone/insert_startcode.c |   8 +-
 drivers/mxc/vpu_malone/vpu_b0.c           | 233 +++++++++++-----------
 drivers/mxc/vpu_malone/vpu_b0.h           |  15 +-
 3 files changed, 122 insertions(+), 134 deletions(-)

diff --git a/drivers/mxc/vpu_malone/insert_startcode.c b/drivers/mxc/vpu_malone/insert_startcode.c
index 082a77a11366..1aa0bc2d51d4 100644
--- a/drivers/mxc/vpu_malone/insert_startcode.c
+++ b/drivers/mxc/vpu_malone/insert_startcode.c
@@ -153,7 +153,7 @@ static int VC1CreateNALSeqHeader(unsigned char *pHeader, int *pHeaderLen,
 	nHeaderLen = nCodecSize - 1;
 	if ((4+nHeaderLen) > nMaxHeader) {
 		nHeaderLen = nMaxHeader - 4;
-		vpu_dbg(LVL_ERR, "error: header length %d overrun !!! \r\n", nCodecSize);
+		vpu_err("error: header length %d overrun !!! \r\n", nCodecSize);
 	}
 	memcpy(pHeader, pCodecPri+1, nHeaderLen);
 
@@ -627,8 +627,7 @@ struct VPU_FMT_INFO_ARV *get_arv_info(struct vpu_ctx *ctx, u_int8 *src, u_int32
 
 	arv_frame = kzalloc(sizeof(struct VPU_FMT_INFO_ARV), GFP_KERNEL);
 	if (IS_ERR_OR_NULL(arv_frame)) {
-		vpu_dbg(LVL_ERR, "%s() error: arv_frame alloc failed\n",
-				__func__);
+		vpu_err("%s() error: arv_frame alloc failed\n", __func__);
 		goto err;
 	}
 
@@ -641,8 +640,7 @@ struct VPU_FMT_INFO_ARV *get_arv_info(struct vpu_ctx *ctx, u_int8 *src, u_int32
 
 	arv_frame->slice_offset = kcalloc(arv_frame->slice_num, sizeof(u_int32), GFP_KERNEL);
 	if (IS_ERR_OR_NULL(arv_frame->slice_offset)) {
-		vpu_dbg(LVL_ERR, "%s() error: slice_offset alloc failed\n",
-				__func__);
+		vpu_err("%s() error: slice_offset alloc failed\n", __func__);
 		goto err;
 	}
 
diff --git a/drivers/mxc/vpu_malone/vpu_b0.c b/drivers/mxc/vpu_malone/vpu_b0.c
index f4a0b17ed71a..3b4a8edc6b0a 100644
--- a/drivers/mxc/vpu_malone/vpu_b0.c
+++ b/drivers/mxc/vpu_malone/vpu_b0.c
@@ -438,16 +438,14 @@ static int find_buffer_id(struct vpu_ctx *ctx, u_int32 addr)
 		LumaAddr = p_data_req->phy_addr[0] + p_data_req->data_offset[0];
 		if (LumaAddr == addr) {
 			if (check_vb_is_changed(p_data_req, LumaAddr))
-				vpu_dbg(LVL_ERR,
-					"ctx[%d] frame buffer[%d] is changed\n",
+				vpu_err("ctx[%d] frame buffer[%d] is changed\n",
 					ctx->str_index, i);
 			break;
 		}
 	}
 	up(&This->drv_q_lock);
 	if (i == VPU_MAX_BUFFER) {
-		vpu_dbg(LVL_ERR,
-			"error: ctx[%d] can't find id based on address(0x%x)\n",
+		vpu_err("error: ctx[%d] can't find id based on address(0x%x)\n",
 			ctx->str_index, addr);
 		return -1;
 	}
@@ -972,13 +970,13 @@ static int vpu_dec_queue_qbuf(struct queue_data *queue,
 	struct vb2_buffer *vb;
 
 	if (buf->index >= queue->vb2_q.num_buffers) {
-		vpu_dbg(LVL_ERR, "[%s] buffer index(%d) out of range\n",
+		vpu_err("[%s] buffer index(%d) out of range\n",
 				queue->type ? "CAPTURE" : "OUTPUT", buf->index);
 		return -EINVAL;
 	}
 	vb = queue->vb2_q.bufs[buf->index];
 	if (vb->state != VB2_BUF_STATE_DEQUEUED) {
-		vpu_dbg(LVL_ERR, "[%s] buffer[%d] has been queued before\n",
+		vpu_err("[%s] buffer[%d] has been queued before\n",
 				queue->type ? "CAPTURE" : "OUTPUT", buf->index);
 		return -EINVAL;
 	}
@@ -1182,7 +1180,7 @@ static int alloc_dma_buffer(struct vpu_ctx *ctx, struct dma_buffer *buffer)
 			GFP_KERNEL | GFP_DMA32 | __GFP_NOWARN);
 
 	if (!buffer->dma_virt) {
-		vpu_dbg(LVL_ERR, "error: %s() dma buffer alloc size(%x) fail!\n",
+		vpu_err("error: %s() dma buffer alloc size(%x) fail!\n",
 				__func__,  buffer->dma_size);
 		vpu_dec_event_decode_error(ctx);
 		return -ENOMEM;
@@ -1226,11 +1224,11 @@ static int alloc_mbi_buffer(struct vpu_ctx *ctx, u32 index)
 	u_int32 ret = 0;
 
 	if (index >= ARRAY_SIZE(ctx->mbi_buffer)) {
-		vpu_dbg(LVL_ERR, "request mbi buffer number out of range\n");
+		vpu_err("request mbi buffer number out of range\n");
 		return -EINVAL;
 	}
 	if (!ctx->mbi_size) {
-		vpu_dbg(LVL_ERR, "mbi buffer size is not initialized\n");
+		vpu_err("mbi buffer size is not initialized\n");
 		return -EINVAL;
 	}
 
@@ -1242,7 +1240,7 @@ static int alloc_mbi_buffer(struct vpu_ctx *ctx, u32 index)
 	mbi_buffer->dma_size = ctx->mbi_size;
 	ret = alloc_dma_buffer(ctx, mbi_buffer);
 	if (ret) {
-		vpu_dbg(LVL_ERR, "error: alloc mbi buffer[%d] fail\n", index);
+		vpu_err("error: alloc mbi buffer[%d] fail\n", index);
 		return ret;
 	}
 
@@ -1265,7 +1263,7 @@ static int alloc_dcp_buffer(struct vpu_ctx *ctx, uint32_t index)
 	dcp_buffer->dma_size = DCP_SIZE;
 	ret = alloc_dma_buffer(ctx, dcp_buffer);
 	if (ret) {
-		vpu_dbg(LVL_ERR, "error: alloc dcp buffer[%d] fail\n", index);
+		vpu_err("error: alloc dcp buffer[%d] fail\n", index);
 		return ret;
 	}
 
@@ -1330,14 +1328,13 @@ static int v4l2_ioctl_reqbufs(struct file *file,
 		return -EINVAL;
 
 	if (vb2_is_streaming(&q_data->vb2_q)) {
-		vpu_dbg(LVL_ERR, "%s reqbufs during streaming\n",
+		vpu_err("%s reqbufs during streaming\n",
 			q_data->type ? "CAPTURE" : "OUTPUT");
 		return -EINVAL;
 	}
 
 	if (reqbuf->count > 0 && !q_data->sizeimage[0]) {
-		vpu_dbg(LVL_ERR,
-			"sizeimage isn't initialized, %s reqbufs fail\n",
+		vpu_err("sizeimage isn't initialized, %s reqbufs fail\n",
 			q_data->type ? "CAPTURE" : "OUTPUT");
 		return -EINVAL;
 	}
@@ -1383,7 +1380,7 @@ static int v4l2_ioctl_querybuf(struct file *file,
 				buf->m.offset |= (q_data->type << MMAP_BUF_TYPE_SHIFT);
 		}
 	} else
-		vpu_dbg(LVL_ERR, "error: %s() return ret=%d\n", __func__, ret);
+		vpu_err("error: %s() return ret=%d\n", __func__, ret);
 
 	return ret;
 }
@@ -1414,7 +1411,7 @@ static void vpu_dec_receive_ts(struct vpu_ctx *ctx,
 		ctx->output_ts = input_ts;
 
 	if (down_interruptible(&ctx->tsm_lock)) {
-		vpu_dbg(LVL_ERR, "%s() get tsm lock fail\n", __func__);
+		vpu_err("%s() get tsm lock fail\n", __func__);
 		return;
 	}
 
@@ -1470,13 +1467,13 @@ static int v4l2_ioctl_qbuf(struct file *file,
 		p_data_req->data_offset[1] = buf->m.planes[1].data_offset;
 		up(&q_data->drv_q_lock);
 	} else {
-		vpu_dbg(LVL_ERR, "qbuf invalid buf type : %d\n", buf->type);
+		vpu_err("qbuf invalid buf type : %d\n", buf->type);
 		return -EINVAL;
 	}
 
 	ret = vpu_dec_queue_qbuf(q_data, buf);
 	if (ret) {
-		vpu_dbg(LVL_ERR, "error: %s() return ret=%d\n", __func__, ret);
+		vpu_err("error: %s() return ret=%d\n", __func__, ret);
 		return ret;
 	}
 	v4l2_update_stream_addr(ctx, 0);
@@ -1489,7 +1486,7 @@ static void vpu_dec_send_ts(struct vpu_ctx *ctx, struct v4l2_buffer *buf)
 	TSM_TIMESTAMP ts;
 
 	if (down_interruptible(&ctx->tsm_lock)) {
-		vpu_dbg(LVL_ERR, "%s() get tsm lock fail\n", __func__);
+		vpu_err("%s() get tsm lock fail\n", __func__);
 		return;
 	}
 
@@ -1517,7 +1514,7 @@ static void vpu_dec_valid_ts(struct vpu_ctx *ctx,
 	WARN_ON(!ctx || !ctx->tsm);
 
 	if (down_interruptible(&ctx->tsm_lock)) {
-		vpu_dbg(LVL_ERR, "%s() get tsm lock fail\n", __func__);
+		vpu_err("%s() get tsm lock fail\n", __func__);
 		return;
 	}
 
@@ -1538,7 +1535,7 @@ static void vpu_dec_skip_ts(struct vpu_ctx *ctx)
 	WARN_ON(!ctx || !ctx->tsm);
 
 	if (down_interruptible(&ctx->tsm_lock)) {
-		vpu_dbg(LVL_ERR, "%s() get tsm lock fail\n", __func__);
+		vpu_err("%s() get tsm lock fail\n", __func__);
 		return;
 	}
 
@@ -1570,7 +1567,7 @@ static int v4l2_ioctl_dqbuf(struct file *file,
 	ret = vpu_dec_queue_dqbuf(q_data, buf, file->f_flags & O_NONBLOCK);
 
 	if (ret) {
-		vpu_dbg(LVL_ERR, "error: %s() return ret=%d\n", __func__, ret);
+		vpu_err("error: %s() return ret=%d\n", __func__, ret);
 		return ret;
 	}
 
@@ -1726,10 +1723,10 @@ static int v4l2_ioctl_streamon(struct file *file,
 	if (!ret)
 		v4l2_update_stream_addr(ctx, 0);
 	else
-		vpu_dbg(LVL_ERR, "error: %s() return ret=%d\n", __func__, ret);
+		vpu_err("error: %s() return ret=%d\n", __func__, ret);
 
 	if (ctx->hang_status) {
-		vpu_dbg(LVL_ERR, "%s(): not succeed and some instance are blocked\n", __func__);
+		vpu_err("%s(): not succeed and some instance are blocked\n", __func__);
 		return -EINVAL;
 	}
 	if (ret)
@@ -1799,7 +1796,7 @@ static int v4l2_ioctl_streamoff(struct file *file,
 
 	ret = vpu_dec_queue_disable(q_data, i);
 	if (ctx->hang_status) {
-		vpu_dbg(LVL_ERR, "%s(): not succeed and some instance are blocked\n", __func__);
+		vpu_err("%s(): not succeed and some instance are blocked\n", __func__);
 		ret = -EINVAL;
 	}
 
@@ -1841,7 +1838,7 @@ static void vpu_dec_set_tsm_frame_rate(struct vpu_ctx *ctx)
 	WARN_ON(!ctx || !ctx->tsm);
 
 	if (down_interruptible(&ctx->tsm_lock)) {
-		vpu_dbg(LVL_ERR, "%s() get tsm lock fail\n", __func__);
+		vpu_err("%s() get tsm lock fail\n", __func__);
 		return;
 	}
 	numerator = ctx->fixed_frame_interval.numerator;
@@ -2057,7 +2054,7 @@ static int v4l2_custom_s_ctrl(struct v4l2_ctrl *ctrl)
 		ctx->bs_h_threshold = ctrl->val;
 		break;
 	default:
-		vpu_dbg(LVL_ERR, "%s() Invalid costomer control(%d)\n",
+		vpu_err("%s() Invalid costomer control(%d)\n",
 				__func__, ctrl->id);
 		return -EINVAL;
 	}
@@ -2080,7 +2077,7 @@ static int v4l2_custom_g_ctrl(struct v4l2_ctrl *ctrl)
 		}
 	}
 	if (!ctrl_cfg) {
-		vpu_dbg(LVL_ERR, "%s() Invalid costomer control(%d)\n",
+		vpu_err("%s() Invalid costomer control(%d)\n",
 				__func__, ctrl->id);
 		return -EINVAL;
 	}
@@ -2102,7 +2099,7 @@ static int v4l2_custom_g_ctrl(struct v4l2_ctrl *ctrl)
 		ctrl->val = ctx->pSeqinfo->uVUIPresent;
 		break;
 	default:
-		vpu_dbg(LVL_ERR, "%s() Invalid costomer control(%d)\n",
+		vpu_err("%s() Invalid costomer control(%d)\n",
 				__func__, ctrl->id);
 		return -EINVAL;
 	}
@@ -2124,7 +2121,7 @@ static int v4l2_dec_g_v_ctrl(struct v4l2_ctrl *ctrl)
 		ctrl->val = ctx->pSeqinfo->uNumDPBFrms + ctx->pSeqinfo->uNumRefFrms;
 		break;
 	default:
-		vpu_dbg(LVL_ERR, "%s() Invalid control(%d)\n",
+		vpu_err("%s() Invalid control(%d)\n",
 				__func__, ctrl->id);
 		return -EINVAL;
 	}
@@ -2152,7 +2149,7 @@ static int add_stand_g_ctrl(struct vpu_ctx *This, uint32_t start)
 				);
 		if (This->ctrl_handler.error ||
 				!This->ctrls[i+start]) {
-			vpu_dbg(LVL_ERR, "%s() v4l2_ctrl_new_std failed(%d) This->ctrls[%d](%p)\n",
+			vpu_err("%s() v4l2_ctrl_new_std failed(%d) This->ctrls[%d](%p)\n",
 					__func__, This->ctrl_handler.error, i+start, This->ctrls[i+start]);
 			return This->ctrl_handler.error;
 		}
@@ -2188,7 +2185,7 @@ static int add_custom_s_ctrl(struct vpu_ctx *This, uint32_t start)
 
 		if (This->ctrl_handler.error ||
 				!This->ctrls[i+start]) {
-			vpu_dbg(LVL_ERR, "%s() failed(%d) This->ctrls[%d](%p)\n",
+			vpu_err("%s() failed(%d) This->ctrls[%d](%p)\n",
 					__func__, This->ctrl_handler.error, i+start, This->ctrls[i+start]);
 			return This->ctrl_handler.error;
 		}
@@ -2215,7 +2212,7 @@ static int add_custom_g_ctrl(struct vpu_ctx *This, uint32_t start)
 
 		if (This->ctrl_handler.error ||
 				!This->ctrls[i+start]) {
-			vpu_dbg(LVL_ERR, "%s() failed(%d) This->ctrls[%d](%p)\n",
+			vpu_err("%s() failed(%d) This->ctrls[%d](%p)\n",
 					__func__, This->ctrl_handler.error, i+start, This->ctrls[i+start]);
 			return This->ctrl_handler.error;
 		}
@@ -2234,7 +2231,7 @@ static int add_dec_ctrl(struct vpu_ctx *This)
 		return -EINVAL;
 
 	if (CNT_CTRLS_DEC > V4L2_MAX_CTRLS) {
-		vpu_dbg(LVL_ERR, "error: v4l2 decode controls added count excedds the limit\n");
+		vpu_err("error: v4l2 decode controls added count excedds the limit\n");
 		return -EINVAL;
 	}
 
@@ -2256,7 +2253,7 @@ static int ctrls_setup_decoder(struct vpu_ctx *This)
 	v4l2_ctrl_handler_init(&This->ctrl_handler,
 			CNT_CTRLS_DEC);
 	if (This->ctrl_handler.error) {
-		vpu_dbg(LVL_ERR, "%s() v4l2_ctrl_handler_init failed(%d)\n",
+		vpu_err("%s() v4l2_ctrl_handler_init failed(%d)\n",
 				__func__, This->ctrl_handler.error);
 
 		return This->ctrl_handler.error;
@@ -2327,29 +2324,28 @@ static int add_scode_vpu(struct vpu_ctx *ctx, u_int32 uStrBufIdx, VPU_PADDING_SC
 
 	if (start != ctx->stream_buffer.dma_phy ||
 			end != ctx->stream_buffer.dma_phy + ctx->stream_buffer.dma_size) {
-		vpu_dbg(LVL_ERR, "error: %s(), start or end pointer cross-border\n", __func__);
+		vpu_err("error: %s(), start or end pointer cross-border\n", __func__);
 		return 0;
 	}
 	if (wptr < start || wptr > end) {
-		vpu_dbg(LVL_ERR, "error: %s(), wptr pointer cross-border\n", __func__);
+		vpu_err("error: %s(), wptr pointer cross-border\n", __func__);
 		return 0;
 	}
 	if (rptr < start || rptr > end) {
-		vpu_dbg(LVL_ERR, "error: %s(), rptr pointer cross-border\n", __func__);
+		vpu_err("error: %s(), rptr pointer cross-border\n", __func__);
 		return 0;
 	}
 
 	buffer = kzalloc(SCODE_SIZE, GFP_KERNEL); //for eos data
-	if (!buffer) {
-		vpu_dbg(LVL_ERR, "error:  eos buffer alloc fail\n");
+	if (!buffer)
 		return 0;
-	}
+
 	atomic64_add(SCODE_SIZE, &ctx->statistic.total_alloc_size);
 	plbuffer = (uint32_t *)buffer;
 	if (wptr - start < ctx->stream_buffer.dma_size)
 		pbbuffer = (uint8_t *)(ctx->stream_buffer.dma_virt + wptr - start);
 	else {
-		vpu_dbg(LVL_ERR, "error: return wptr(0x%x), start(0x%x) is not valid\n", wptr, start);
+		vpu_err("error: return wptr(0x%x), start(0x%x) is not valid\n", wptr, start);
 		goto error;
 	}
 
@@ -2357,7 +2353,7 @@ static int add_scode_vpu(struct vpu_ctx *ctx, u_int32 uStrBufIdx, VPU_PADDING_SC
 	if (((u_int64)pbbuffer)%4 != 0) {
 		int i;
 		if (end%4 != 0) {
-			vpu_dbg(LVL_ERR, "end address of stream not aligned by 4 bytes !\n");
+			vpu_err("end address of stream not aligned by 4 bytes !\n");
 			goto error;
 		}
 		pad_bytes = 4 - (((u_int64)pbbuffer)%4);
@@ -2465,7 +2461,7 @@ static int add_scode_vpu(struct vpu_ctx *ctx, u_int32 uStrBufIdx, VPU_PADDING_SC
 			pad_bytes += SCODE_SIZE;
 		} else	{
 			//shouldn't enter here: suppose space is enough since add_eos() only be called in FIFO LOW
-			vpu_dbg(LVL_ERR, "No enough space to insert EOS, size=%d !\n", rptr - wptr);
+			vpu_err("No enough space to insert EOS, size=%d !\n", rptr - wptr);
 			memcpy(pbbuffer, buffer, rptr - wptr);
 			wptr += (rptr - wptr);
 			pad_bytes += (rptr - wptr);
@@ -2649,15 +2645,14 @@ static void vpu_dec_cleanup_cmd(struct vpu_ctx *ctx)
 
 	mutex_lock(&ctx->cmd_lock);
 	if (ctx->pending) {
-		vpu_dbg(LVL_ERR,
-			"ctx[%d]'s cmd(%s) is not finished yet\n",
+		vpu_err("ctx[%d]'s cmd(%s) is not finished yet\n",
 			ctx->str_index, get_cmd_str(ctx->pending->request));
 		put_cmd_request(ctx, ctx->pending);
 		ctx->pending = NULL;
 	}
 	list_for_each_entry_safe(request, tmp, &ctx->cmd_q, list) {
 		list_del_init(&request->list);
-		vpu_dbg(LVL_ERR, "cmd(%s) of ctx[%d] is missed\n",
+		vpu_err("cmd(%s) of ctx[%d] is missed\n",
 				get_cmd_str(request->request), ctx->str_index);
 		put_cmd_request(ctx, request);
 	}
@@ -2696,14 +2691,14 @@ static void vpu_dec_request_cmd(struct vpu_ctx *ctx,
 	u32 i;
 
 	if (cmdnum > VPU_DEC_CMD_DATA_MAX_NUM) {
-		vpu_dbg(LVL_ERR, "cmd(%s)'s data number(%d) > %d, drop it\n",
+		vpu_err("cmd(%s)'s data number(%d) > %d, drop it\n",
 			get_cmd_str(cmdid), cmdnum, VPU_DEC_CMD_DATA_MAX_NUM);
 		return;
 	}
 
 	request = get_cmd_request(ctx, cmdid);
 	if (!request) {
-		vpu_dbg(LVL_ERR, "cmd(%s) of ctx[%d] is missed\n",
+		vpu_err("cmd(%s) of ctx[%d] is missed\n",
 				get_cmd_str(cmdid), idx);
 		return;
 	}
@@ -2762,7 +2757,7 @@ static u32 transfer_buffer_to_firmware(struct vpu_ctx *ctx,
 
 
 	if (ctx->stream_buffer.dma_size < buffer_size + MIN_SPACE) {
-		vpu_dbg(LVL_ERR, "circular buffer size is set too small\n");
+		vpu_err("circular buffer size is set too small\n");
 		return 0;
 	}
 	if (!ctx->start_code_bypass)
@@ -2838,7 +2833,7 @@ static void v4l2_transfer_buffer_to_firmware(struct queue_data *This, struct vb2
 	if (ctx->start_flag == true) {
 		ret = alloc_vpu_buffer(ctx);
 		if (ret) {
-			vpu_dbg(LVL_ERR, "alloc vpu buffer fail\n");
+			vpu_err("alloc vpu buffer fail\n");
 			return;
 		}
 
@@ -2915,15 +2910,15 @@ static int copy_buffer_to_stream(struct vpu_ctx *ctx, void *buffer, uint32_t len
 
 	if (start != ctx->stream_buffer.dma_phy ||
 			end != ctx->stream_buffer.dma_phy + ctx->stream_buffer.dma_size) {
-		vpu_dbg(LVL_ERR, "error: %s(), start or end pointer cross-border\n", __func__);
+		vpu_err("error: %s(), start or end pointer cross-border\n", __func__);
 		return 0;
 	}
 	if (wptr < start || wptr > end) {
-		vpu_dbg(LVL_ERR, "error: %s(), wptr pointer cross-border\n", __func__);
+		vpu_err("error: %s(), wptr pointer cross-border\n", __func__);
 		return 0;
 	}
 	if (rptr < start || rptr > end) {
-		vpu_dbg(LVL_ERR, "error: %s(), rptr pointer cross-border\n", __func__);
+		vpu_err("error: %s(), rptr pointer cross-border\n", __func__);
 		return 0;
 	}
 
@@ -2966,12 +2961,12 @@ static int send_abort_cmd(struct vpu_ctx *ctx)
 	size = add_scode(ctx, 0, BUFABORT_PADDING_TYPE, false);
 	record_log_info(ctx, LOG_PADDING, 0, 0);
 	if (size < 0)
-		vpu_dbg(LVL_ERR, "%s(): failed to fill abort padding data\n", __func__);
+		vpu_err("%s(): failed to fill abort padding data\n", __func__);
 	v4l2_vpu_send_cmd(ctx, ctx->str_index, VID_API_CMD_ABORT, 1, &size);
 	reinit_completion(&ctx->completion);
 	if (!wait_for_completion_timeout(&ctx->completion, msecs_to_jiffies(1000))) {
 		ctx->hang_status = true;
-		vpu_dbg(LVL_ERR, "the path id:%d firmware timeout after send VID_API_CMD_ABORT\n",
+		vpu_err("the path id:%d firmware timeout after send VID_API_CMD_ABORT\n",
 					ctx->str_index);
 		return -EBUSY;
 	}
@@ -2993,7 +2988,7 @@ static int send_stop_cmd(struct vpu_ctx *ctx)
 	reinit_completion(&ctx->stop_cmp);
 	if (!wait_for_completion_timeout(&ctx->stop_cmp, msecs_to_jiffies(1000))) {
 		ctx->hang_status = true;
-		vpu_dbg(LVL_ERR, "the path id:%d firmware hang after send VID_API_CMD_STOP\n", ctx->str_index);
+		vpu_err("the path id:%d firmware hang after send VID_API_CMD_STOP\n", ctx->str_index);
 		return -EBUSY;
 	}
 
@@ -3389,7 +3384,7 @@ static void report_buffer_done(struct vpu_ctx *ctx, void *frame_info)
 
 	buffer_id = find_buffer_id(ctx, FrameInfo[1]);
 	if (buffer_id == -1) {
-		vpu_dbg(LVL_ERR, "%s() ctx[%d] not find buffer id: %d, addr: 0x%x\n",
+		vpu_err("%s() ctx[%d] not find buffer id: %d, addr: 0x%x\n",
 				__func__, ctx->str_index, fs_id, FrameInfo[1]);
 		return;
 	}
@@ -3400,11 +3395,11 @@ static void report_buffer_done(struct vpu_ctx *ctx, void *frame_info)
 			ctx->frm_dis_delay--;
 			return;
 		}
-		vpu_dbg(LVL_ERR, "error: find buffer_id(%d) and firmware return id(%d) doesn't match\n",
+		vpu_err("error: find buffer_id(%d) and firmware return id(%d) doesn't match\n",
 				buffer_id, fs_id);
 	}
 	if (ctx->q_data[V4L2_DST].vb2_reqs[buffer_id].status != FRAME_DECODED)
-		vpu_dbg(LVL_ERR, "error: buffer(%d) need to set FRAME_READY, but previous state %s is not FRAME_DECODED\n",
+		vpu_err("error: buffer(%d) need to set FRAME_READY, but previous state %s is not FRAME_DECODED\n",
 				buffer_id, bufstat[ctx->q_data[V4L2_DST].vb2_reqs[buffer_id].status]);
 
 	set_data_req_status(&ctx->q_data[V4L2_DST].vb2_reqs[buffer_id],
@@ -3422,7 +3417,7 @@ static void report_buffer_done(struct vpu_ctx *ctx, void *frame_info)
 			vb2_buffer_done(p_data_req->vb2_buf,
 					VB2_BUF_STATE_DONE);
 		else
-			vpu_dbg(LVL_ERR, "warning: wait_rst_done(%d) check buffer(%d) state(%d)\n",
+			vpu_err("warning: wait_rst_done(%d) check buffer(%d) state(%d)\n",
 					ctx->wait_rst_done, buffer_id, p_data_req->vb2_buf->state);
 	}
 	up(&This->drv_q_lock);
@@ -3579,8 +3574,7 @@ static u32 get_consumed_pic_bytesused(struct vpu_ctx *ctx,
 	vpu_dbg(LVL_BIT_PIC_ADDR, "<0x%08x 0x%08x>, %8d, %8d\n",
 		pic_start_addr, pic_end_addr, pic_size, consumed_pic_bytesused);
 	if (consumed_pic_bytesused < pic_size)
-		vpu_dbg(LVL_ERR,
-			"ErrorAddr:[%d] Start(0x%x), End(0x%x), preEnd(0x%x)\n",
+		vpu_err("ErrorAddr:[%d] Start(0x%x), End(0x%x), preEnd(0x%x)\n",
 			ctx->str_index,
 			pic_start_addr,
 			pic_end_addr,
@@ -3754,13 +3748,13 @@ static bool check_seq_info_is_valid(u32 ctx_id, MediaIPFW_Video_SeqInfo *info)
 		return false;
 
 	if (!info->uHorRes || !info->uVerRes) {
-		vpu_dbg(LVL_ERR, "ctx[%d] invalid seq info : %d x %d\n",
+		vpu_err("ctx[%d] invalid seq info : %d x %d\n",
 			ctx_id, info->uHorRes, info->uVerRes);
 		return false;
 	}
 	if (info->uHorRes > VPU_DEC_MAX_WIDTH ||
 			info->uVerRes > VPU_DEC_MAX_HEIGTH) {
-		vpu_dbg(LVL_ERR, "ctx[%d] invalid seq info : %d x %d\n",
+		vpu_err("ctx[%d] invalid seq info : %d x %d\n",
 			ctx_id, info->uHorRes, info->uVerRes);
 		return false;
 	}
@@ -3793,7 +3787,7 @@ static void vpu_api_event_handler(struct vpu_ctx *ctx, u_int32 uStrIdx, u_int32
 	record_log_info(ctx, LOG_EVENT, uEvent, pStrBufDesc->rptr);
 
 	if (ctx == NULL) {
-		vpu_dbg(LVL_ERR, "receive event: 0x%X after instance released, ignore it\n", uEvent);
+		vpu_err("receive event: 0x%X after instance released, ignore it\n", uEvent);
 		return;
 	}
 
@@ -3804,7 +3798,7 @@ static void vpu_api_event_handler(struct vpu_ctx *ctx, u_int32 uStrIdx, u_int32
 		case VID_API_EVENT_FIFO_LOW:
 			return;
 		default:
-			vpu_dbg(LVL_ERR, "receive event: 0x%X after stopped, ignore it\n", uEvent);
+			vpu_err("receive event: 0x%X after stopped, ignore it\n", uEvent);
 			return;
 		}
 	}
@@ -3886,7 +3880,7 @@ static void vpu_api_event_handler(struct vpu_ctx *ctx, u_int32 uStrIdx, u_int32
 
 		buffer_id = find_buffer_id(ctx, event_data[0]);
 		if (buffer_id == -1) {
-			vpu_dbg(LVL_ERR, "error: %s() ctx[%d] not find buffer id: %d, addr: 0x%x\n",
+			vpu_err("error: %s() ctx[%d] not find buffer id: %d, addr: 0x%x\n",
 					__func__, ctx->str_index, uDecFrmId, event_data[0]);
 			vpu_dec_valid_ts(ctx,
 					consumed_pic_bytesused,
@@ -3903,11 +3897,11 @@ static void vpu_api_event_handler(struct vpu_ctx *ctx, u_int32 uStrIdx, u_int32
 						NULL);
 				break;
 			}
-			vpu_dbg(LVL_ERR, "error: VID_API_EVENT_PIC_DECODED address and id doesn't match\n");
+			vpu_err("error: VID_API_EVENT_PIC_DECODED address and id doesn't match\n");
 		}
 		p_data_req = &This->vb2_reqs[buffer_id];
 		if (p_data_req->status != FRAME_FREE)
-			vpu_dbg(LVL_ERR, "error: buffer(%d) need to set FRAME_DECODED, but previous state %s is not FRAME_FREE\n",
+			vpu_err("error: buffer(%d) need to set FRAME_DECODED, but previous state %s is not FRAME_FREE\n",
 					buffer_id, bufstat[ctx->q_data[V4L2_DST].vb2_reqs[buffer_id].status]);
 		set_data_req_status(p_data_req, FRAME_DECODED);
 		if (ctx->pSeqinfo->uProgressive == 1)
@@ -3988,7 +3982,7 @@ static void vpu_api_event_handler(struct vpu_ctx *ctx, u_int32 uStrIdx, u_int32
 		vpu_dbg(LVL_INFO, "VID_API_EVENT_REQ_FRAME_BUFF, type=%d, size=%ld\n", pFSREQ->eType, sizeof(MEDIA_PLAYER_FSREQ));
 		if (pFSREQ->eType == MEDIAIP_DCP_REQ) {
 			if (ctx->dcp_count >= MAX_DCP_NUM) {
-				vpu_dbg(LVL_ERR, "error: request dcp buffers number is over MAX_DCP_NUM\n");
+				vpu_err("error: request dcp buffers number is over MAX_DCP_NUM\n");
 				break;
 			}
 			if (alloc_dcp_buffer(ctx, ctx->dcp_count))
@@ -4204,10 +4198,10 @@ static void vpu_api_event_handler(struct vpu_ctx *ctx, u_int32 uStrIdx, u_int32
 		break;
 	case VID_API_EVENT_FINISHED: {
 		if (ctx->eos_stop_added == false)
-			vpu_dbg(LVL_ERR, "warning: receive VID_API_EVENT_FINISHED before eos_stop_added set\n");
+			vpu_err("warning: receive VID_API_EVENT_FINISHED before eos_stop_added set\n");
 		ctx->eos_stop_added = false;
 		if (ctx->firmware_finished == true)
-			vpu_dbg(LVL_ERR, "warning: receive VID_API_EVENT_FINISHED when firmware_finished == true\n");
+			vpu_err("warning: receive VID_API_EVENT_FINISHED when firmware_finished == true\n");
 		ctx->firmware_finished = true;
 		vpu_dbg(LVL_BIT_FLOW, "ctx[%d] FINISHED\n", ctx->str_index);
 		vpu_dbg(LVL_INFO, "receive VID_API_EVENT_FINISHED and notfiy app eos\n");
@@ -4219,7 +4213,7 @@ static void vpu_api_event_handler(struct vpu_ctx *ctx, u_int32 uStrIdx, u_int32
 	case VID_API_EVENT_FIRMWARE_XCPT: {
 		char *xcpt_info = (char*)event_data;
 
-		vpu_dbg(LVL_ERR, "warning: VID_API_EVENT_FIRMWARE_XCPT,exception info: %s\n", xcpt_info);
+		vpu_err("warning: VID_API_EVENT_FIRMWARE_XCPT,exception info: %s\n", xcpt_info);
 		ctx->hang_status = true;
 		send_eos_event(ctx);
 		}
@@ -4231,7 +4225,7 @@ static void vpu_api_event_handler(struct vpu_ctx *ctx, u_int32 uStrIdx, u_int32
 		vpu_dec_event_decode_error(ctx);
 		break;
 	default:
-		vpu_dbg(LVL_ERR, "warning: uEvent %d is not handled\n", uEvent);
+		vpu_err("warning: uEvent %d is not handled\n", uEvent);
 		break;
 	}
 	vpu_dbg(LVL_INFO, "leave %s, uEvent %d\n", __func__, uEvent);
@@ -4290,7 +4284,7 @@ static int vpu_mu_init(struct vpu_dev *dev)
 	 */
 	np = of_find_compatible_node(NULL, NULL, "fsl,imx8-mu0-vpu-m0");
 	if (!np) {
-		vpu_dbg(LVL_ERR, "error: Cannot find MU entry in device tree\n");
+		vpu_err("error: Cannot find MU entry in device tree\n");
 		return -EINVAL;
 	}
 	dev->mu_base_virtaddr = of_iomap(np, 0);
@@ -4299,7 +4293,7 @@ static int vpu_mu_init(struct vpu_dev *dev)
 	ret = of_property_read_u32_index(np,
 				"fsl,vpu_ap_mu_id", 0, &vpu_mu_id);
 	if (ret) {
-		vpu_dbg(LVL_ERR, "error: Cannot get mu_id %d\n", ret);
+		vpu_err("error: Cannot get mu_id %d\n", ret);
 		return -EINVAL;
 	}
 
@@ -4310,7 +4304,7 @@ static int vpu_mu_init(struct vpu_dev *dev)
 	ret = devm_request_irq(&dev->plat_dev->dev, irq, fsl_vpu_mu_isr,
 				IRQF_EARLY_RESUME, "vpu_mu_isr", (void *)dev);
 	if (ret) {
-		vpu_dbg(LVL_ERR, "error: request_irq failed %d, error = %d\n", irq, ret);
+		vpu_err("error: request_irq failed %d, error = %d\n", irq, ret);
 		return -EINVAL;
 	}
 
@@ -4341,9 +4335,9 @@ static void release_vpu_ctx(struct vpu_ctx *ctx)
 	}
 
 	if (atomic64_read(&ctx->statistic.total_alloc_size) != 0)
-		vpu_dbg(LVL_ERR, "error: memory leak for vpu kalloc buffer\n");
+		vpu_err("error: memory leak for vpu kalloc buffer\n");
 	if (atomic64_read(&ctx->statistic.total_dma_size) != 0)
-		vpu_dbg(LVL_ERR, "error: memory leak for vpu dma buffer\n");
+		vpu_err("error: memory leak for vpu dma buffer\n");
 
 	mutex_destroy(&ctx->instance_mutex);
 	mutex_destroy(&ctx->cmd_lock);
@@ -4417,7 +4411,7 @@ static void send_msg_queue(struct vpu_ctx *ctx, struct event_msg *msg)
 
 	ret = kfifo_in(&ctx->msg_fifo, msg, sizeof(u_int32) * (MSG_WORD_LENGTH + msg->msgnum));
 	if (ret != sizeof(u_int32) * (MSG_WORD_LENGTH + msg->msgnum))
-		vpu_dbg(LVL_ERR, "There is no memory for msg fifo, ret=%d\n", ret);
+		vpu_err("There is no memory for msg fifo, ret=%d\n", ret);
 }
 
 static bool receive_msg_queue(struct vpu_ctx *ctx, struct event_msg *msg)
@@ -4427,14 +4421,14 @@ static bool receive_msg_queue(struct vpu_ctx *ctx, struct event_msg *msg)
 	if (kfifo_len(&ctx->msg_fifo) >= sizeof(u_int32) * MSG_WORD_LENGTH) {
 		ret = kfifo_out(&ctx->msg_fifo, msg, sizeof(u_int32) * MSG_WORD_LENGTH);
 		if (ret != sizeof(u_int32) * MSG_WORD_LENGTH) {
-			vpu_dbg(LVL_ERR, "kfifo_out msg word has error, ret=%d\n", ret);
+			vpu_err("kfifo_out msg word has error, ret=%d\n", ret);
 			return false;
 		} else {
 			if (msg->msgnum > 0) {
 				if (kfifo_len(&ctx->msg_fifo) >= sizeof(u_int32) * msg->msgnum) {
 					ret = kfifo_out(&ctx->msg_fifo, msg->msgdata, sizeof(u_int32) * msg->msgnum);
 					if (ret != sizeof(u_int32) * msg->msgnum) {
-						vpu_dbg(LVL_ERR, "kfifo_out msg data has error, ret=%d\n", ret);
+						vpu_err("kfifo_out msg data has error, ret=%d\n", ret);
 						return false;
 					} else
 						return true;
@@ -4475,7 +4469,7 @@ static void vpu_msg_run_work(struct work_struct *work)
 		mutex_unlock(&dev->dev_mutex);
 	}
 	if (rpc_MediaIPFW_Video_message_check(This) == API_MSG_BUFFER_ERROR)
-		vpu_dbg(LVL_ERR, "error: message size is too big to handle\n");
+		vpu_err("error: message size is too big to handle\n");
 }
 static void vpu_msg_instance_work(struct work_struct *work)
 {
@@ -4657,7 +4651,7 @@ static void init_vb2_queue(struct queue_data *This, unsigned int type, struct vp
 	vb2_q->dev = &ctx->dev->plat_dev->dev;
 	ret = vb2_queue_init(vb2_q);
 	if (ret)
-		vpu_dbg(LVL_ERR, "error: %s vb2_queue_init() failed (%d)!\n",
+		vpu_err("error: %s vb2_queue_init() failed (%d)!\n",
 				__func__, ret);
 	else
 		This->vb2_q_inited = true;
@@ -4707,7 +4701,7 @@ static int vpu_firmware_download(struct vpu_dev *This)
 			);
 
 	if (ret) {
-		vpu_dbg(LVL_ERR, "error: %s() request fw %s failed(%d)\n",
+		vpu_err("error: %s() request fw %s failed(%d)\n",
 			__func__, M0FW_FILENAME, ret);
 
 		if (This->m0_pfw) {
@@ -4785,7 +4779,7 @@ static int create_instance_dbglog_file(struct vpu_ctx *ctx)
 
 	ctx->dbglog_dir = debugfs_create_dir(ctx->dbglog_name, ctx->dev->debugfs_root);
 	if (!ctx->dbglog_dir) {
-		vpu_dbg(LVL_ERR, "error: %s() ctx->dbglog_dir == NULL\n", __func__);
+		vpu_err("error: %s() ctx->dbglog_dir == NULL\n", __func__);
 		return -EINVAL;
 	}
 	debugfs_create_file("dbglog", VERIFY_OCTAL_PERMISSIONS(0444),
@@ -4854,7 +4848,7 @@ static int create_fwlog_file(struct vpu_dev *dev)
 	if (dev->debugfs_root == NULL) {
 		dev->debugfs_root = debugfs_create_dir("vpu", NULL);
 		if (!dev->debugfs_root) {
-			vpu_dbg(LVL_ERR, "error: create debugfs_root fail\n");
+			vpu_err("error: create debugfs_root fail\n");
 			return -EINVAL;
 		}
 	}
@@ -4867,7 +4861,7 @@ static int create_fwlog_file(struct vpu_dev *dev)
 						dev,
 						&fwlog_fops);
 	if (!dev->debugfs_fwlog) {
-		vpu_dbg(LVL_ERR, "error: create debugfs_fwlog fail\n");
+		vpu_err("error: create debugfs_fwlog fail\n");
 		return -EINVAL;
 	}
 
@@ -5321,7 +5315,7 @@ static int alloc_vpu_buffer(struct vpu_ctx *ctx)
 		ctx->stream_buffer.dma_size = vpu_max_bufsize;
 		ret = alloc_dma_buffer(ctx, &ctx->stream_buffer);
 		if (ret) {
-			vpu_dbg(LVL_ERR, "error: alloc stream buffer fail!\n");
+			vpu_err("error: alloc stream buffer fail!\n");
 			return ret;
 		}
 	}
@@ -5330,7 +5324,7 @@ static int alloc_vpu_buffer(struct vpu_ctx *ctx)
 		ctx->udata_buffer.dma_size = UDATA_BUFFER_SIZE;
 		ret = alloc_dma_buffer(ctx, &ctx->udata_buffer);
 		if (ret) {
-			vpu_dbg(LVL_ERR, "error: alloc udata buffer fail!\n");
+			vpu_err("error: alloc udata buffer fail!\n");
 			free_dma_buffer(ctx, &ctx->stream_buffer);
 			return ret;
 		}
@@ -5352,7 +5346,7 @@ static int open_crc_file(struct vpu_ctx *ctx)
 			ctx->str_index);
 	ctx->crc_fp = filp_open(crc_file, O_RDWR | O_CREAT, 0664);
 	if (IS_ERR(ctx->crc_fp)) {
-		vpu_dbg(LVL_ERR, "error: open crc file fail\n");
+		vpu_err("error: open crc file fail\n");
 		ret = -1;
 	}
 	ctx->pos = 0;
@@ -5421,7 +5415,7 @@ static int v4l2_open(struct file *filp)
 
 	ctx->instance_wq = alloc_workqueue("vpu_instance", WQ_UNBOUND | WQ_MEM_RECLAIM, 1);
 	if (!ctx->instance_wq) {
-		vpu_dbg(LVL_ERR, "error: %s unable to alloc workqueue for ctx\n", __func__);
+		vpu_err("error: %s unable to alloc workqueue for ctx\n", __func__);
 		ret = -ENOMEM;
 		goto err_alloc_wq;
 	}
@@ -5432,7 +5426,7 @@ static int v4l2_open(struct file *filp)
 	if (kfifo_alloc(&ctx->msg_fifo,
 				sizeof(struct event_msg) * VID_API_MESSAGE_LIMIT,
 				GFP_KERNEL)) {
-		vpu_dbg(LVL_ERR, "fail to alloc fifo when open\n");
+		vpu_err("fail to alloc fifo when open\n");
 		ret = -ENOMEM;
 		goto err_alloc_fifo;
 	}
@@ -5469,7 +5463,6 @@ static int v4l2_open(struct file *filp)
 	}
 	ctx->pSeqinfo = kzalloc(sizeof(MediaIPFW_Video_SeqInfo), GFP_KERNEL);
 	if (!ctx->pSeqinfo) {
-		vpu_dbg(LVL_ERR, "error: pSeqinfo alloc fail\n");
 		ret = -ENOMEM;
 		goto err_alloc_seq;
 	}
@@ -5483,7 +5476,7 @@ static int v4l2_open(struct file *filp)
 	if (!dev->fw_is_ready) {
 		ret = vpu_firmware_download(dev);
 		if (ret) {
-			vpu_dbg(LVL_ERR, "error: vpu_firmware_download fail\n");
+			vpu_err("error: vpu_firmware_download fail\n");
 			mutex_unlock(&dev->dev_mutex);
 			goto err_firmware_load;
 		}
@@ -5491,7 +5484,7 @@ static int v4l2_open(struct file *filp)
 		if (!ctx->dev->firmware_started) {
 			reinit_completion(&ctx->dev->start_cmp);
 			if (!wait_for_completion_timeout(&ctx->dev->start_cmp, msecs_to_jiffies(10000))) {
-				vpu_dbg(LVL_ERR, "error: don't get start interrupt\n");
+				vpu_err("error: don't get start interrupt\n");
 				ret = -1;
 				goto err_firmware_load;
 			}
@@ -5534,7 +5527,7 @@ static int v4l2_open(struct file *filp)
 	clear_bit(ctx->str_index, &dev->instance_mask);
 err_find_index:
 	if (atomic64_read(&ctx->statistic.total_alloc_size) != 0)
-		vpu_dbg(LVL_ERR, "error: memory leak for vpu kalloc buffer\n");
+		vpu_err("error: memory leak for vpu kalloc buffer\n");
 	kfree(ctx);
 	pm_runtime_put_sync(dev->generic_dev);
 
@@ -5730,7 +5723,7 @@ static int swreset_vpu_firmware(struct vpu_dev *dev, u_int32 idx)
 
 	reinit_completion(&dev->start_cmp);
 	if (!wait_for_completion_timeout(&dev->start_cmp, msecs_to_jiffies(10000))) {
-		vpu_dbg(LVL_ERR, "error: %s() fail\n", __func__);
+		vpu_err("error: %s() fail\n", __func__);
 		return -1;
 	}
 	dev->firmware_started = true;
@@ -5751,7 +5744,7 @@ static int parse_dt_info(struct vpu_dev *dev, struct device_node *np)
 
 	ret = of_property_read_u32(np, "core_type", &core_type);
 	if (ret) {
-		vpu_dbg(LVL_ERR, "error: Cannot get core num %d\n", ret);
+		vpu_err("error: Cannot get core num %d\n", ret);
 		return -EINVAL;
 	}
 	if (core_type == 2)
@@ -5760,24 +5753,24 @@ static int parse_dt_info(struct vpu_dev *dev, struct device_node *np)
 		dev->plat_type = IMX8QXP;
 	reserved_node = of_parse_phandle(np, "boot-region", 0);
 	if (!reserved_node) {
-		vpu_dbg(LVL_ERR, "error: boot-region of_parse_phandle error\n");
+		vpu_err("error: boot-region of_parse_phandle error\n");
 		return -ENODEV;
 	}
 
 	if (of_address_to_resource(reserved_node, 0, &reserved_res)) {
-		vpu_dbg(LVL_ERR, "error: boot-region of_address_to_resource error\n");
+		vpu_err("error: boot-region of_address_to_resource error\n");
 		return -EINVAL;
 	}
 	dev->m0_p_fw_space_phy = reserved_res.start;
 	dev->m0_boot_size = reserved_res.end - reserved_res.start;
 	reserved_node = of_parse_phandle(np, "rpc-region", 0);
 	if (!reserved_node) {
-		vpu_dbg(LVL_ERR, "error: rpc-region of_parse_phandle error\n");
+		vpu_err("error: rpc-region of_parse_phandle error\n");
 		return -ENODEV;
 	}
 
 	if (of_address_to_resource(reserved_node, 0, &reserved_res)) {
-		vpu_dbg(LVL_ERR, "error: rpc-region of_address_to_resource error\n");
+		vpu_err("error: rpc-region of_address_to_resource error\n");
 		return -EINVAL;
 	}
 	dev->m0_rpc_phy = reserved_res.start;
@@ -5785,7 +5778,7 @@ static int parse_dt_info(struct vpu_dev *dev, struct device_node *np)
 
 	ret = of_property_read_u32(np, "reg-csr", &csr_base);
 	if (ret) {
-		vpu_dbg(LVL_ERR, "error: Cannot get csr offset %d\n", ret);
+		vpu_err("error: Cannot get csr offset %d\n", ret);
 		return -EINVAL;
 	}
 	dev->csr_base = ioremap(csr_base, 8); //for csr0 offset and cpuwait
@@ -5802,7 +5795,7 @@ static int create_vpu_video_device(struct vpu_dev *dev)
 
 	dev->pvpu_decoder_dev = video_device_alloc();
 	if (!dev->pvpu_decoder_dev) {
-		vpu_dbg(LVL_ERR, "video device alloc for decoder fail\n");
+		vpu_err("video device alloc for decoder fail\n");
 		return -ENOMEM;
 	}
 	strlcpy(dev->pvpu_decoder_dev->name,
@@ -5820,7 +5813,7 @@ static int create_vpu_video_device(struct vpu_dev *dev)
 			VFL_TYPE_GRABBER,
 			DECODER_NODE_NUMBER);
 	if (ret) {
-		vpu_dbg(LVL_ERR, "error: %s unable to register video decoder device\n",
+		vpu_err("error: %s unable to register video decoder device\n",
 				__func__
 				);
 		video_device_release(dev->pvpu_decoder_dev);
@@ -5852,7 +5845,7 @@ static int init_vpudev_parameters(struct vpu_dev *dev)
 
 	ret = vpu_mu_init(dev);
 	if (ret) {
-		vpu_dbg(LVL_ERR, "error: %s vpu mu init failed\n", __func__);
+		vpu_err("error: %s vpu mu init failed\n", __func__);
 		return ret;
 	}
 
@@ -5861,7 +5854,7 @@ static int init_vpudev_parameters(struct vpu_dev *dev)
 			dev->m0_boot_size
 			);
 	if (!dev->m0_p_fw_space_vir) {
-		vpu_dbg(LVL_ERR, "error: failed to remap space for M0 firmware\n");
+		vpu_err("error: failed to remap space for M0 firmware\n");
 		return -ENOMEM;
 	}
 
@@ -5871,7 +5864,7 @@ static int init_vpudev_parameters(struct vpu_dev *dev)
 			dev->m0_rpc_size
 			);
 	if (!dev->m0_rpc_virt) {
-		vpu_dbg(LVL_ERR, "error: failed to remap space for rpc shared memory\n");
+		vpu_err("error: failed to remap space for rpc shared memory\n");
 		return -ENOMEM;
 	}
 
@@ -5898,20 +5891,20 @@ static int vpu_probe(struct platform_device *pdev)
 	res = platform_get_resource(pdev, IORESOURCE_MEM, 0);
 	dev->regs_base = devm_ioremap_resource(&pdev->dev, res);
 	if (IS_ERR(dev->regs_base)) {
-		vpu_dbg(LVL_ERR, "error: %s could not map regs_base\n", __func__);
+		vpu_err("error: %s could not map regs_base\n", __func__);
 		ret = PTR_ERR(dev->regs_base);
 		goto err_put_dev;
 	}
 
 	ret = parse_dt_info(dev, np);
 	if (ret) {
-		vpu_dbg(LVL_ERR, "error: %s parse device tree fail\n", __func__);
+		vpu_err("error: %s parse device tree fail\n", __func__);
 		goto err_dev_iounmap;
 	}
 
 	ret = v4l2_device_register(&pdev->dev, &dev->v4l2_dev);
 	if (ret) {
-		vpu_dbg(LVL_ERR, "error: %s unable to register v4l2 dev\n", __func__);
+		vpu_err("error: %s unable to register v4l2 dev\n", __func__);
 		goto err_dev_iounmap;
 	}
 
@@ -5919,27 +5912,27 @@ static int vpu_probe(struct platform_device *pdev)
 
 	ret = create_vpu_video_device(dev);
 	if (ret) {
-		vpu_dbg(LVL_ERR, "error: %s create vpu video device fail\n", __func__);
+		vpu_err("error: %s create vpu video device fail\n", __func__);
 		goto err_unreg_v4l2;
 	}
 
 	if (!dev->mu_ipcHandle) {
 		ret = sc_ipc_getMuID(&mu_id);
 		if (ret) {
-			vpu_dbg(LVL_ERR, "error: --- sc_ipc_getMuID() cannot obtain mu id SCI error! (%d)\n", ret);
+			vpu_err("error: --- sc_ipc_getMuID() cannot obtain mu id SCI error! (%d)\n", ret);
 			goto err_rm_vdev;
 		}
 
 		ret = sc_ipc_open(&dev->mu_ipcHandle, mu_id);
 		if (ret) {
-			vpu_dbg(LVL_ERR, "error: --- sc_ipc_getMuID() cannot open MU channel to SCU error! (%d)\n", ret);
+			vpu_err("error: --- sc_ipc_getMuID() cannot open MU channel to SCU error! (%d)\n", ret);
 			goto err_rm_vdev;
 		}
 	}
 
 	dev->workqueue = alloc_workqueue("vpu", WQ_UNBOUND | WQ_MEM_RECLAIM, 1);
 	if (!dev->workqueue) {
-		vpu_dbg(LVL_ERR, "error: %s unable to alloc workqueue\n", __func__);
+		vpu_err("error: %s unable to alloc workqueue\n", __func__);
 		ret = -ENOMEM;
 		goto err_rm_vdev;
 	}
@@ -5953,7 +5946,7 @@ static int vpu_probe(struct platform_device *pdev)
 
 	ret = init_vpudev_parameters(dev);
 	if (ret) {
-		vpu_dbg(LVL_ERR, "error: failed to init parameters for vpudev\n");
+		vpu_err("error: failed to init parameters for vpudev\n");
 		goto err_poweroff;
 	}
 
@@ -6069,7 +6062,7 @@ static int vpu_suspend(struct device *dev)
 		v4l2_vpu_send_snapshot(vpudev);
 		reinit_completion(&vpudev->snap_done_cmp);
 		if (!wait_for_completion_timeout(&vpudev->snap_done_cmp, msecs_to_jiffies(1000))) {
-			vpu_dbg(LVL_ERR, "error: wait for vpu decoder snapdone event timeout!\n");
+			vpu_err("error: wait for vpu decoder snapdone event timeout!\n");
 			return -1;
 		}
 	}
@@ -6115,7 +6108,7 @@ static int resume_from_snapshot(struct vpu_dev *vpudev)
 	/*wait for firmware resotre done*/
 	reinit_completion(&vpudev->start_cmp);
 	if (!wait_for_completion_timeout(&vpudev->start_cmp, msecs_to_jiffies(1000))) {
-		vpu_dbg(LVL_ERR, "error: wait for vpu decoder resume done timeout!\n");
+		vpu_err("error: wait for vpu decoder resume done timeout!\n");
 		ret = -1;
 	}
 
diff --git a/drivers/mxc/vpu_malone/vpu_b0.h b/drivers/mxc/vpu_malone/vpu_b0.h
index 80c5e5df0f6e..97c4f72ced25 100644
--- a/drivers/mxc/vpu_malone/vpu_b0.h
+++ b/drivers/mxc/vpu_malone/vpu_b0.h
@@ -401,12 +401,9 @@ struct vpu_ctx {
 	struct mutex cmd_lock;
 };
 
-#define LVL_INFO		3
-#define LVL_EVENT		2
-#define LVL_WARN		1
-#define LVL_ERR			0
-#define LVL_MASK		0xf
-
+#define LVL_WARN		(1 << 1)
+#define LVL_EVENT		(1 << 2)
+#define LVL_INFO		(1 << 3)
 #define LVL_BIT_CMD		(1 << 4)
 #define LVL_BIT_EVT		(1 << 5)
 #define LVL_BIT_TS		(1 << 6)
@@ -419,11 +416,11 @@ struct vpu_ctx {
 #define LVL_BIT_FLOW		(1 << 13)
 #define LVL_BIT_FRAME_COUNT	(1 << 14)
 
+#define vpu_err(fmt, arg...) pr_info("[VPU Decoder]\t " fmt, ## arg)
+
 #define vpu_dbg(level, fmt, arg...) \
 	do { \
-		if ((vpu_dbg_level_decoder & LVL_MASK) >= (level)) \
-			pr_info("[VPU Decoder]\t " fmt, ## arg); \
-		else if ((vpu_dbg_level_decoder & (~LVL_MASK)) & level) \
+		if (vpu_dbg_level_decoder & level) \
 			pr_info("[VPU Decoder]\t " fmt, ## arg); \
 	} while (0)
 
-- 
2.17.1

